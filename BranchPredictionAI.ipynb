{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rXknk8hUDvEQ"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MgI2NBMeD4nl",
        "outputId": "823eecf2-a356-497a-8319-5421bdd3d26f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>branch_addr</th>\n",
              "      <th>taken</th>\n",
              "      <th>history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6ffcd6e7c25b</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6ffcd6e7c27b</td>\n",
              "      <td>1</td>\n",
              "      <td>1,1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6ffcd6e7c275</td>\n",
              "      <td>0</td>\n",
              "      <td>1,1,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6ffcd6e7c27b</td>\n",
              "      <td>1</td>\n",
              "      <td>1,1,0,1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6ffcd6e7c275</td>\n",
              "      <td>0</td>\n",
              "      <td>1,1,0,1,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305986</th>\n",
              "      <td>6ffcc3296999</td>\n",
              "      <td>0</td>\n",
              "      <td>1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305987</th>\n",
              "      <td>6ffcc3298e85</td>\n",
              "      <td>1</td>\n",
              "      <td>0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305988</th>\n",
              "      <td>6ffcc32969c9</td>\n",
              "      <td>0</td>\n",
              "      <td>0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305989</th>\n",
              "      <td>6ffcc3247b74</td>\n",
              "      <td>1</td>\n",
              "      <td>1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305990</th>\n",
              "      <td>6ffcc32ee210</td>\n",
              "      <td>1</td>\n",
              "      <td>1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,1,1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>305991 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         branch_addr  taken                                  history\n",
              "0       6ffcd6e7c25b      1                                        1\n",
              "1       6ffcd6e7c27b      1                                      1,1\n",
              "2       6ffcd6e7c275      0                                    1,1,0\n",
              "3       6ffcd6e7c27b      1                                  1,1,0,1\n",
              "4       6ffcd6e7c275      0                                1,1,0,1,0\n",
              "...              ...    ...                                      ...\n",
              "305986  6ffcc3296999      0  1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0\n",
              "305987  6ffcc3298e85      1  0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1\n",
              "305988  6ffcc32969c9      0  0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0\n",
              "305989  6ffcc3247b74      1  1,1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,1\n",
              "305990  6ffcc32ee210      1  1,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,1,1\n",
              "\n",
              "[305991 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Print head and tail of the dataset\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5_0EgRgbD70p",
        "outputId": "ef741e59-3a35-4ab1-f5ae-18b10dd3b82e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "branch_addr    0\n",
              "taken          0\n",
              "history        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for missing values\n",
        "dataset.isnull().sum() # No missing values exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "_llYft1yENrA",
        "outputId": "75d14738-22f4-4966-e9be-3eda8df0da04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Outcome distribution'}, xlabel='taken'>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset[\"taken\"].value_counts().plot.bar(title=\"Outcome distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "u29e6mViExah",
        "outputId": "58123827-a6f8-41bc-bd23-28354f024087"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>305991.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.397714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.489427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               taken\n",
              "count  305991.000000\n",
              "mean        0.397714\n",
              "std         0.489427\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         1.000000\n",
              "max         1.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AqjKOn29FpiV"
      },
      "outputs": [],
      "source": [
        "# Convert 'history' column to numeric arrays\n",
        "dataset['history'] = dataset['history'].str.split(',').apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "# Further processing if you need to create histogram based on individual element frequencies\n",
        "# all_history_values = list(itertools.chain.from_iterable(dataset['history']))\n",
        "# plt.hist(all_history_values, bins=20)\n",
        "# plt.title(\"Distribution of History Values\")\n",
        "# plt.xlabel(\"Value\")\n",
        "# plt.ylabel(\"Frequency\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "mH88SWlbGeZl",
        "outputId": "aa6377e6-3d3e-45a0-bf56-51e4823067b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                                       [1]\n",
              "1                                                    [1, 1]\n",
              "2                                                 [1, 1, 0]\n",
              "3                                              [1, 1, 0, 1]\n",
              "4                                           [1, 1, 0, 1, 0]\n",
              "                                ...                        \n",
              "305986    [1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, ...\n",
              "305987    [0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, ...\n",
              "305988    [0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, ...\n",
              "305989    [1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, ...\n",
              "305990    [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
              "Name: history, Length: 305991, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['history']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j8B2QbhfJprz"
      },
      "outputs": [],
      "source": [
        "# Add a new column named position\n",
        "\n",
        "dataset.insert(0, 'position', range(1, len(dataset) + 1))\n",
        "\n",
        "# Using direct assignment:\n",
        "dataset['position'] = range(1, len(dataset) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QjevEc6SIxMp"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train/test (80%/20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('taken', axis=1), dataset['taken'], test_size=0.2, random_state=None, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "sveYjQp4I4U4",
        "outputId": "34a47603-9613-4be0-f4ea-aa6920321ec8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         1\n",
              "1         1\n",
              "2         0\n",
              "3         1\n",
              "4         0\n",
              "         ..\n",
              "244787    0\n",
              "244788    0\n",
              "244789    0\n",
              "244790    0\n",
              "244791    1\n",
              "Name: taken, Length: 244792, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(244792, 3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train['branch_addr'] = X_train['branch_addr'].apply(lambda x: int(x, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bmLH1mlBMxzT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# One-hot encode the 'history' column\n",
        "mlb = MultiLabelBinarizer()\n",
        "history_encoded = mlb.fit_transform(X_train['history'])\n",
        "\n",
        "# Create a new DataFrame for the encoded history\n",
        "history_encoded_df = pd.DataFrame(history_encoded, columns=mlb.classes_, index=X_train.index)\n",
        "\n",
        "# Drop the 'position', and 'history' columns and concatenate the encoded history\n",
        "X_train_new = pd.concat([X_train.drop(columns=['position', 'history']), history_encoded_df], axis=1)\n",
        "\n",
        "clf = SVC(verbose=True)          # SVC will print iteration progress itself\n",
        "# clf.fit(X_train_new[:2000], y_train[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9015/1540489122.py:9: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  X_test_new = pd.concat([X_test.drop(columns=['branch_addr', 'position', 'history']), history_encoded_df], axis=1)\n"
          ]
        },
        {
          "ename": "NotFittedError",
          "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Drop the 'branch_addr', 'position', and 'history' columns and concatenate the encoded history\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_test_new \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbranch_addr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m]), history_encoded_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:809\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform classification on samples in X.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 or -1 is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m        Class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_ties \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    812\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreak_ties must be False when decision_function_shape is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m         )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "# One-hot encode the 'history' column\n",
        "mlb = MultiLabelBinarizer()\n",
        "history_encoded = mlb.fit_transform(X_test['history'])\n",
        "\n",
        "# Create a new DataFrame for the encoded history\n",
        "history_encoded_df = pd.DataFrame(history_encoded, columns=mlb.classes_, index=X_test.index)\n",
        "\n",
        "# Drop the 'branch_addr', 'position', and 'history' columns and concatenate the encoded history\n",
        "X_test_new = pd.concat([X_test.drop(columns=['branch_addr', 'position', 'history']), history_encoded_df], axis=1)\n",
        "\n",
        "predictions = clf.predict(X_test_new[:300])\n",
        "print(\"Predicted class labels:\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'predictions' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test[:\u001b[38;5;241m300\u001b[39m], \u001b[43mpredictions\u001b[49m, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Taken\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTaken\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ],
      "source": [
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test[:300], predictions, target_names=['Not Taken', 'Taken']))\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "accuracy = accuracy_score(y_test[:300], predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2-bit predictor accuracy: 0.568\n"
          ]
        }
      ],
      "source": [
        "# 2-bit classifier (2-bit branch predictor)\n",
        "\n",
        "class TwoBitPredictor:\n",
        "    def __init__(self):\n",
        "        self.state = 0  # 00: strongly not taken, 01: weakly not taken, 10: weakly taken, 11: strongly taken\n",
        "\n",
        "    def predict(self):\n",
        "        return self.state >= 2\n",
        "\n",
        "    def update(self, taken):\n",
        "        if taken:\n",
        "            if self.state < 3:\n",
        "                self.state += 1\n",
        "        else:\n",
        "            if self.state > 0:\n",
        "                self.state -= 1\n",
        "\n",
        "# Initialize the predictor\n",
        "predictor = TwoBitPredictor()\n",
        "# Simulate the prediction process\n",
        "predictions = []\n",
        "for outcome in y_test:\n",
        "    predictions.append(predictor.predict())\n",
        "    predictor.update(outcome)\n",
        "# Calculate accuracy\n",
        "accuracy_2bit = accuracy_score(y_test, predictions)\n",
        "print(f\"2-bit predictor accuracy: {accuracy_2bit:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-bit predictor accuracy: 0.415\n"
          ]
        }
      ],
      "source": [
        "# 1-bit classifier (1-bit branch predictor)\n",
        "\n",
        "class OneBitPredictor:\n",
        "    def __init__(self):\n",
        "        self.state = 0  # 0: not taken, 1: taken\n",
        "    def predict(self):\n",
        "        return self.state\n",
        "    def update(self, taken):\n",
        "        if taken:\n",
        "            self.state = 1\n",
        "        else:\n",
        "            self.state = 0\n",
        "\n",
        "# Initialize the predictor\n",
        "predictor = OneBitPredictor()\n",
        "# Simulate the prediction process\n",
        "predictions = []\n",
        "for outcome in y_test:\n",
        "    predictions.append(predictor.predict())\n",
        "    predictor.update(outcome)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_1bit = accuracy_score(y_test, predictions)\n",
        "print(f\"1-bit predictor accuracy: {accuracy_1bit:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'accuracy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m     30\u001b[0m accuracy_gshare \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, predictions)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGSHARE predictor accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maccuracy\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
          ]
        }
      ],
      "source": [
        "class GSHAREPredictor:\n",
        "    def __init__(self, table_bits=15):\n",
        "        self.size = 1 << table_bits  # Size of the Pattern History Table (PHT)\n",
        "        self.pht = [2] * self.size   # Initialize counters to 'weakly taken' (value 2)\n",
        "\n",
        "    def predict(self, pc):\n",
        "        index = int(pc, 16) % self.size  # Convert hexadecimal string to integer\n",
        "        counter = self.pht[index]\n",
        "        return counter >= 2  # Predict 'taken' if counter is 2 or 3\n",
        "\n",
        "    def update(self, pc, taken):\n",
        "        index = int(pc, 16) % self.size  # Convert hexadecimal string to integer\n",
        "        counter = self.pht[index]\n",
        "        if taken:\n",
        "            if counter < 3:\n",
        "                self.pht[index] += 1\n",
        "        else:\n",
        "            if counter > 0:\n",
        "                self.pht[index] -= 1\n",
        "\n",
        "# Initialize the predictor\n",
        "predictor = GSHAREPredictor()\n",
        "# Simulate the prediction process\n",
        "predictions = []\n",
        "for pc, outcome in zip(X_test['branch_addr'], y_test):\n",
        "    predictions.append(predictor.predict(pc))\n",
        "    predictor.update(pc, outcome)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_gshare = accuracy_score(y_test, predictions)\n",
        "print(f\"GSHARE predictor accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perceptron predictor accuracy: 0.950\n"
          ]
        }
      ],
      "source": [
        "# Perceptron Neural Network\n",
        "\n",
        "class PerceptronBranchPredictor:\n",
        "    def __init__(self, history_length=6, threshold=0):\n",
        "        self.history_length = history_length\n",
        "        self.threshold = threshold\n",
        "        # Initialize weights and bias\n",
        "        self.weights = [0] * history_length\n",
        "        self.bias = 0\n",
        "        # Initialize global history with 0 (representing 'not taken')\n",
        "        self.history = [0] * history_length\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"\n",
        "        Predicts the outcome of a branch.\n",
        "        Returns 1 for 'taken' and 0 for 'not taken'.\n",
        "        \"\"\"\n",
        "        y = self.bias\n",
        "        for w, h in zip(self.weights, self.history):\n",
        "            y += w * h\n",
        "        return 1 if y >= 0 else 0\n",
        "\n",
        "    def update(self, actual_outcome):\n",
        "        \"\"\"\n",
        "        Updates the perceptron weights based on the actual outcome.\n",
        "        actual_outcome: 1 for 'taken', 0 for 'not taken'\n",
        "        \"\"\"\n",
        "        prediction = self.predict()\n",
        "        if prediction != actual_outcome or abs(self.bias + sum(w * h for w, h in zip(self.weights, self.history))) <= self.threshold:\n",
        "            # Update weights and bias\n",
        "            for i in range(self.history_length):\n",
        "                self.weights[i] += actual_outcome * self.history[i]\n",
        "            self.bias += actual_outcome\n",
        "        # Update history\n",
        "        self.history = [actual_outcome] + self.history[:-1]\n",
        "\n",
        "# Initialize the predictor\n",
        "predictor = PerceptronBranchPredictor(history_length=6)\n",
        "# Simulate the prediction process\n",
        "for i, outcome in enumerate(y_test):\n",
        "    prediction = predictor.predict()\n",
        "    predictor.update(outcome)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_perceptron = accuracy_score(y_test, predictions)\n",
        "print(f\"Perceptron predictor accuracy: {accuracy_perceptron:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare accuracies of different branch prediction implementations\n",
        "accuracies = {\n",
        "    \"1-bit Predictor\": accuracy_1bit,\n",
        "    \"2-bit Predictor\": accuracy_2bit,\n",
        "    \"GSHARE Predictor\": accuracy_gshare,\n",
        "    \"Perceptron Predictor\": accuracy_perceptron\n",
        "}\n",
        "\n",
        "# Plot the accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'orange', 'green', 'red'], width=0.4)\n",
        "\n",
        "# Add accuracy values on top of each bar\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.title(\"Accuracy Comparison of Branch Prediction Implementations\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Branch Prediction Method\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Definition of a BranchNet model in Pytorch\n",
        "\"\"\"\n",
        "\n",
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BranchNetTrainingPhaseKnobs:\n",
        "  \"\"\"Set of knobs for reconfiguring a BranchNet model during training phases.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.quantize_convolution = False\n",
        "    self.quantize_sumpooling = False\n",
        "    self.quantize_hidden_fc = False\n",
        "    self.quantize_final_fc = False\n",
        "\n",
        "    self.prune_filters = False\n",
        "    self.prune_fc_layers = False\n",
        "\n",
        "    self.lut_convolution = False\n",
        "\n",
        "    self.freeze_sumpooling_batchnorm_params = False\n",
        "    self.freeze_hidden_fc_params = False\n",
        "\n",
        "\n",
        "class Quantize(torch.autograd.Function):\n",
        "  \"\"\"Quantizes its input within [0,1] or [-1,+1]\"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, x, unsigned, precision):\n",
        "    if unsigned:\n",
        "      scale = ((1 << precision) - 1)\n",
        "      return torch.round(x * scale) / scale\n",
        "    else:\n",
        "      if precision == 1:\n",
        "        return -1 + 2 * (x > 0).float()\n",
        "      else: \n",
        "        scale = ((1 << (precision - 1)) - 1)\n",
        "        return torch.round(x * scale) / scale\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    return grad_output.clone(), None, None\n",
        "\n",
        "\n",
        "def lists_have_equal_length(list_of_lists):\n",
        "  \"\"\"helper function to check that the length of lists are equals\"\"\"\n",
        "  set_of_lengths = set(map(len, list_of_lists))\n",
        "  return len(set_of_lengths) <= 1\n",
        "\n",
        "\n",
        "# Extraction here happens from the configs folder where all the yaml files reside\n",
        "def extract_slice_history(x, config, global_shift, slice_id):\n",
        "  \"\"\"Extract a portion of history for a slice.\"\"\"\n",
        "\n",
        "  total_history_size = x.shape[1]\n",
        "  slice_size = config['history_lengths'][slice_id]\n",
        "  pooling_width = config['pooling_widths'][slice_id]\n",
        "  assert slice_size <= total_history_size\n",
        "\n",
        "  if config['shifting_pooling'][slice_id]:\n",
        "    slice_shift = global_shift % pooling_width\n",
        "    inputs = []\n",
        "    for i in range(x.shape[0]):\n",
        "      slice_end = total_history_size - slice_shift[i]\n",
        "      slice_start = slice_end - slice_size\n",
        "      inputs.append(x[i, slice_start:slice_end])\n",
        "    return torch.stack(inputs)\n",
        "  else:\n",
        "    return x[:, -slice_size:]\n",
        "\n",
        "\n",
        "class Slice(nn.Module):\n",
        "  \"\"\"A Pytorch neural network module class to define a BranchNet slice\n",
        "    corresponding to some portion of the history.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config, slice_id, training_phase_knobs):\n",
        "    \"\"\"Creates all the layers and computes the expected output size.\n",
        "    \"\"\"\n",
        "    super(Slice, self).__init__()\n",
        "    history_length = config['history_lengths'][slice_id]\n",
        "    conv_filters = config['conv_filters'][slice_id]\n",
        "    conv_width = config['conv_widths'][slice_id]\n",
        "    pooling_width = config['pooling_widths'][slice_id]\n",
        "    embedding_dims = config['embedding_dims']\n",
        "    use_Transformer_encoder = config['use_Transformer_encoder']\n",
        "    pc_hash_bits = config['pc_hash_bits']\n",
        "    hash_dir_with_pc = config['hash_dir_with_pc']\n",
        "\n",
        "    # remember slice configuration\n",
        "    self.config = config\n",
        "    self.slice_id = slice_id\n",
        "    self.lut_convolution = training_phase_knobs.lut_convolution\n",
        "    self.quantize_sumpooling = training_phase_knobs.quantize_sumpooling\n",
        "    self.training_phase_knobs = training_phase_knobs\n",
        "\n",
        "    if training_phase_knobs.prune_filters:\n",
        "      self.pruning_mask = nn.Parameter(torch.zeros(\n",
        "          1, self.config['conv_filters'][slice_id], 1), requires_grad=False)\n",
        "\n",
        "    # Declare all the neural network layers\n",
        "    index_width = pc_hash_bits if hash_dir_with_pc else (pc_hash_bits + 1)\n",
        "    if self.lut_convolution:\n",
        "      if config['combined_hash_convolution']:\n",
        "        assert not hash_dir_with_pc\n",
        "        self.build_hashing_metadata()\n",
        "        self.combined_lookup_table = nn.Embedding(\n",
        "            2 ** config['combined_hash_convolution_width'],\n",
        "            conv_filters)\n",
        "        self.combined_lookup_table.weight.requires_grad = False\n",
        "      else:\n",
        "        self.lookup_tables = nn.ModuleList()\n",
        "        for i in range(conv_width):\n",
        "          self.lookup_tables.append(\n",
        "              nn.Embedding(2 ** index_width, conv_filters))\n",
        "          self.lookup_tables[i].weight.requires_grad = False \n",
        "    else:\n",
        "      if config['combined_hash_convolution']:\n",
        "        assert not hash_dir_with_pc\n",
        "        self.build_hashing_metadata()\n",
        "        self.combined_embedding_table = nn.Embedding(\n",
        "            2 ** config['combined_hash_convolution_width'],\n",
        "            embedding_dims)\n",
        "        self.combined_conv = nn.Conv1d(embedding_dims, conv_filters, 1)\n",
        "        self.batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "      else:\n",
        "        self.embedding_table = nn.Embedding(2 ** index_width, embedding_dims)\n",
        "        if(use_Transformer_encoder):\n",
        "          self.Transformer_encoder = nn.TransformerEncoderLayer(d_model=embedding_dims, nhead=8, dim_feedforward=512, dropout=0.3)\n",
        "        self.conv = nn.Conv1d(embedding_dims, conv_filters, conv_width)\n",
        "        self.batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "\n",
        "    self.pooling = nn.AvgPool1d(pooling_width, padding=0)\n",
        "\n",
        "    if self.quantize_sumpooling:\n",
        "      self.pooling_batchnorm = nn.BatchNorm1d(\n",
        "          conv_filters * self.config['sumpooling_copies'])\n",
        "      if training_phase_knobs.freeze_sumpooling_batchnorm_params:\n",
        "        self.pooling_batchnorm.bias.requires_grad = False\n",
        "        self.pooling_batchnorm.weight.requires_grad = False\n",
        "    else:\n",
        "      self.pooling_batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "\n",
        "\n",
        "    # compute the slice output size\n",
        "    if pooling_width == -1 or (config['shifting_pooling'][slice_id]\n",
        "                               and config['sum_all_if_shifting_pool']):\n",
        "      pooling_output_size = 1\n",
        "    elif pooling_width > 0: \n",
        "      conv_output_size = (history_length - conv_width + 1)\n",
        "      pooling_output_size = conv_output_size // pooling_width\n",
        "    else:\n",
        "      pooling_output_size = (history_length - conv_width + 1)\n",
        "    self.total_output_size = pooling_output_size * conv_filters\n",
        "    if self.quantize_sumpooling:\n",
        "      self.total_output_size *= self.config['sumpooling_copies']\n",
        "    if(self.config['use_lstm']):\n",
        "      self.lstm = nn.LSTM(\n",
        "        input_size=self.config['lstm_inp_dim'],\n",
        "        hidden_size=self.config['lstm_hidden_size'],\n",
        "        bidirectional = self.config['bidirectional'],\n",
        "        batch_first=True\n",
        "      )\n",
        "\n",
        "  def build_hashing_metadata(self):\n",
        "    num_input_bits = ((self.config['pc_hash_bits'] + 1) *\n",
        "                      max(self.config['conv_widths']))\n",
        "    num_output_bits = self.config['combined_hash_convolution_width']\n",
        "\n",
        "    assert num_output_bits < 32\n",
        "    self.hash_metadata = nn.Parameter(torch.randint(\n",
        "        0, 2 ** num_output_bits, size=[num_input_bits], dtype=torch.int64), requires_grad=False)\n",
        "\n",
        "  def hash_using_metadata(self, x, conv_width):\n",
        "    batch_size = x.shape[0]\n",
        "    available_history = x.shape[1]\n",
        "    output_history = available_history + 1 - conv_width\n",
        "    bits_per_conv_pos = self.config['pc_hash_bits'] + 1\n",
        "    zero_tensor = torch.zeros(1,\n",
        "                      dtype=torch.int64, device=x.device)\n",
        "    out = torch.zeros(batch_size, output_history,\n",
        "                      dtype=torch.int64, device=x.device)\n",
        "\n",
        "    for conv_pos in range(conv_width):\n",
        "      history_slice = x[:, available_history - conv_pos - output_history: available_history - conv_pos]\n",
        "      for bit in range(bits_per_conv_pos):\n",
        "        metadata_idx = conv_pos * bits_per_conv_pos + bit\n",
        "        xor_pattern = self.hash_metadata[metadata_idx: metadata_idx + 1]\n",
        "        out = out ^ torch.where((history_slice >> bit) & 1 == 1, xor_pattern, zero_tensor)\n",
        "    \n",
        "    return out\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    history_length = self.config['history_lengths'][self.slice_id]\n",
        "    conv_filters = self.config['conv_filters'][self.slice_id]\n",
        "    conv_width = self.config['conv_widths'][self.slice_id]\n",
        "    pooling_width = self.config['pooling_widths'][self.slice_id]\n",
        "\n",
        "    if self.lut_convolution:\n",
        "      if self.config['combined_hash_convolution']:\n",
        "        x = self.hash_using_metadata(x, conv_width)\n",
        "        x = self.combined_lookup_table(x)\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        if self.training_phase_knobs.prune_filters:\n",
        "          x = x * self.pruning_mask\n",
        "      else:\n",
        "        batch_size = x.shape[0]\n",
        "        num_channels = conv_filters\n",
        "        conv_outputs = torch.zeros(batch_size,\n",
        "                                   num_channels,\n",
        "                                   history_length - conv_width + 1,\n",
        "                                   device=x.device)\n",
        "\n",
        "        for conv_pos in range(conv_width):\n",
        "          temp = self.lookup_tables[conv_pos](\n",
        "              x[:,conv_pos:history_length-conv_width+conv_pos+1])\n",
        "          temp = temp.transpose(1, 2)\n",
        "          conv_outputs += temp\n",
        "        x = conv_outputs\n",
        "        x = self.convolution_activation(x)\n",
        "    else:\n",
        "      # convolution and batch norm layers\n",
        "      if self.config['combined_hash_convolution']:\n",
        "        x = self.hash_using_metadata(x, conv_width)\n",
        "        x = self.combined_embedding_table(x)\n",
        "        x = torch.transpose(x, 1, 2)\n",
        "        x = self.combined_conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.convolution_activation(x)\n",
        "      else:\n",
        "        x = self.embedding_table(x)\n",
        "        if (self.config['use_Transformer_encoder']):          \n",
        "          x = self.Transformer_encoder(x)        \n",
        "        x = torch.transpose(x, 1, 2)                \n",
        "        x = self.conv(x)        \n",
        "        x = self.batchnorm(x)\n",
        "        x = self.convolution_activation(x)\n",
        "\n",
        "    # pooling\n",
        "    if pooling_width == -1 or (self.config['shifting_pooling'][self.slice_id]\n",
        "                               and self.config['sum_all_if_shifting_pool']):\n",
        "      x = torch.sum(x, 2, keepdim=True)\n",
        "    elif pooling_width > 0:\n",
        "      x = self.pooling(x) * pooling_width    \n",
        "    x = self.sumpooling_activation(x)\n",
        "    if(self.config['use_lstm']):\n",
        "      x = x.permute(0, 2, 1)\n",
        "      _ , (x , _ ) = self.lstm(x)\n",
        "      x = x.permute(0, 2, 1)\n",
        "      return x.reshape(-1, self.total_output_size)\n",
        "    else:\n",
        "      return x.view(-1, self.total_output_size)\n",
        "\n",
        "  def get_output_size(self):\n",
        "    \"\"\"Returns the expected output size for the slice\n",
        "    \"\"\"\n",
        "    return self.total_output_size\n",
        "\n",
        "  def convolution_activation(self, x):\n",
        "    \"\"\"Returns post- and pre- quantization activations.\"\"\"\n",
        "    relu_act = nn.ReLU(inplace=True)\n",
        "    sigmoid_act = nn.Sigmoid()\n",
        "    tanh_act = nn.Tanh()\n",
        "    quantize = Quantize.apply\n",
        "\n",
        "    conv_activation_type = self.config['conv_activation']\n",
        "    conv_quantization_bits = self.config['conv_quantization_bits']\n",
        "\n",
        "    if conv_activation_type == 'relu':\n",
        "      x = relu_act(x)\n",
        "      if self.training_phase_knobs.prune_filters:\n",
        "        x = x * self.pruning_mask\n",
        "      assert not self.training_phase_knobs.quantize_convolution\n",
        "      return x\n",
        "    if conv_activation_type == 'sigmoid':\n",
        "      x = sigmoid_act(x)\n",
        "      if self.training_phase_knobs.prune_filters:\n",
        "        x = x * self.pruning_mask\n",
        "      if self.training_phase_knobs.quantize_convolution:\n",
        "        assert conv_quantization_bits > 0\n",
        "        return quantize(x, True, conv_quantization_bits)\n",
        "      else:\n",
        "        return x\n",
        "    if conv_activation_type == 'tanh':\n",
        "      x = tanh_act(x)\n",
        "      if self.training_phase_knobs.prune_filters:\n",
        "        x = x * self.pruning_mask\n",
        "      if self.training_phase_knobs.quantize_convolution:\n",
        "        assert conv_quantization_bits > 0\n",
        "        return quantize(x, False, conv_quantization_bits)\n",
        "      else:\n",
        "        return x\n",
        "\n",
        "    assert False\n",
        "\n",
        "  def sumpooling_activation(self, x):\n",
        "    if self.quantize_sumpooling:\n",
        "      repeat_pattern = [1] * len(x.shape)\n",
        "      repeat_pattern[1] = self.config['sumpooling_copies']\n",
        "      x = x.repeat(*repeat_pattern)\n",
        "\n",
        "    tanh_act = nn.Tanh()\n",
        "    hardtanh_act = nn.Hardtanh()\n",
        "    sigmoid_act = nn.Tanh()\n",
        "    hardsigmoid_act = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
        "    quantize = Quantize.apply\n",
        "\n",
        "    activation = self.config['sumpooling_activation']\n",
        "    quantization_bits = self.config['sumpooling_quantization_bits']\n",
        "\n",
        "    if activation == 'none':\n",
        "      assert quantization_bits == 0\n",
        "      return x\n",
        "    if activation == 'bn_only':\n",
        "      assert quantization_bits == 0\n",
        "      return self.pooling_batchnorm(x)\n",
        "    if activation == 'tanh':\n",
        "      x = tanh_act(self.pooling_batchnorm(x))\n",
        "      if not self.quantize_sumpooling or quantization_bits == 0:\n",
        "        return x\n",
        "      else:\n",
        "        return quantize(x, False, quantization_bits)\n",
        "    if activation == 'hardtanh':\n",
        "      x = hardtanh_act(self.pooling_batchnorm(x))\n",
        "      if not self.quantize_sumpooling or quantization_bits == 0:\n",
        "        return x\n",
        "      else:\n",
        "        return quantize(x, False, quantization_bits)\n",
        "    if activation == 'sigmoid':\n",
        "      x = sigmoid_act(self.pooling_batchnorm(x))\n",
        "      if not self.quantize_sumpooling or quantization_bits == 0:\n",
        "        return x\n",
        "      else:\n",
        "        return quantize(x, True, quantization_bits)\n",
        "    if activation == 'hardsigmoid':\n",
        "      x = hardsigmoid_act(self.pooling_batchnorm(x))\n",
        "      if not self.quantize_sumpooling or quantization_bits == 0:\n",
        "        return x\n",
        "      else:\n",
        "        return quantize(x, True, quantization_bits)\n",
        "\n",
        "    assert False\n",
        "\n",
        "  def setup_pruning_mask(self, useful_channels_for_slice):\n",
        "    indices = torch.LongTensor(useful_channels_for_slice).to(\n",
        "        self.pruning_mask.device).unsqueeze(0).unsqueeze(2)\n",
        "    self.pruning_mask.scatter_(1, indices, 1)\n",
        "    print(self.pruning_mask.view(-1))\n",
        "\n",
        "\n",
        "class FCLayer(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, *, activation, quantize,\n",
        "               quantized_act_bits, quantized_weight_bits, freeze_params,\n",
        "               use_pruning_mask):\n",
        "    super(FCLayer, self).__init__()\n",
        "    self.use_pruning_mask = use_pruning_mask\n",
        "    self.activation = activation\n",
        "    self.quantize = quantize\n",
        "    self.quantized_act_bits = quantized_act_bits\n",
        "    self.quantized_weight_bits = quantized_weight_bits\n",
        "\n",
        "    self.weight = nn.Parameter(torch.empty(output_dim, input_dim),\n",
        "                                     requires_grad=not freeze_params)\n",
        "    self.bias = nn.Parameter(torch.empty(output_dim),\n",
        "                                   requires_grad=not freeze_params)\n",
        "    if activation is not None:\n",
        "      self.batchnorm = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "    if use_pruning_mask:\n",
        "      self.pruning_mask = nn.Parameter(torch.zeros_like(self.bias),\n",
        "                                    requires_grad=False)\n",
        "\n",
        "    self.randomize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    quantize = Quantize.apply\n",
        "\n",
        "    if self.quantize and self.quantized_weight_bits > 0: \n",
        "      self.state_dict()['weight'][:] = torch.clamp(\n",
        "          self.weight.data, -1, 1)\n",
        "      weight = quantize(self.weight, False, self.quantized_weight_bits)\n",
        "    else:\n",
        "      weight = self.weight\n",
        "\n",
        "    x = nn.functional.linear(x, weight, bias=self.bias)\n",
        "    if self.activation is not None:\n",
        "      x = self.activation_layer(x)\n",
        "    if self.use_pruning_mask:\n",
        "      x = x * self.pruning_mask\n",
        "    return x\n",
        "\n",
        "  def activation_layer(self, x):\n",
        "    x = self.batchnorm(x)\n",
        "\n",
        "    quantize = Quantize.apply\n",
        "    relu_act = nn.ReLU(inplace=True)\n",
        "    sigmoid_act = nn.Sigmoid()\n",
        "    tanh_act = nn.Tanh()\n",
        "    hardtanh_act = nn.Hardtanh()\n",
        "    quantize_act = self.quantize and self.quantized_act_bits > 0\n",
        "\n",
        "    if self.activation == 'relu':\n",
        "      assert not quantize_act\n",
        "      x = relu_act(x)\n",
        "    elif self.activation == 'sigmoid':\n",
        "      x = sigmoid_act(x)\n",
        "      if quantize_act:\n",
        "        x = quantize(x, True, self.quantized_act_bits)\n",
        "    elif self.activation == 'tanh':\n",
        "      x = tanh_act(x)\n",
        "      if quantize_act:\n",
        "        x = quantize(x, False, self.quantized_act_bits)\n",
        "    elif self.activation == 'hardtanh':\n",
        "      x = hardtanh_act(x)\n",
        "      if quantize_act:\n",
        "        x = quantize(x, False, self.quantized_act_bits)\n",
        "    else:\n",
        "      assert False\n",
        "\n",
        "    return x\n",
        "\n",
        "  def randomize_weights(self):\n",
        "    output_dim = self.weight.shape[0]\n",
        "    input_dim = self.weight.shape[1]\n",
        "    glorot_init_bound = math.sqrt(2. / (input_dim + output_dim))\n",
        "    if self.quantize and self.quantized_weight_bits > 0:\n",
        "      self.weight.data.uniform_(-1, 1)\n",
        "    else:\n",
        "      self.weight.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "    self.bias.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "\n",
        "  def l1_loss(self):\n",
        "    return torch.sum(torch.abs(self.weight))\n",
        "\n",
        "  def setup_pruning_mask(self, top_neuron_indices):\n",
        "    self.pruning_mask.scatter_(0, top_neuron_indices, 1)\n",
        "    print(self.pruning_mask)\n",
        "\n",
        "\n",
        "class BranchNetMLP(nn.Module):\n",
        "  def __init__(self, config, training_phase_knobs, flattened_input_dim):\n",
        "    super(BranchNetMLP, self).__init__()\n",
        "    self.config = config\n",
        "    self.training_phase_knobs = training_phase_knobs\n",
        "    self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "    next_input_dim = flattened_input_dim\n",
        "    for hidden_output_dim in self.config['hidden_neurons']:\n",
        "      assert hidden_output_dim > 0\n",
        "      self.hidden_layers.append(FCLayer(\n",
        "          next_input_dim, hidden_output_dim,\n",
        "          activation=self.config['hidden_fc_activation'],\n",
        "          quantize=training_phase_knobs.quantize_hidden_fc,\n",
        "          quantized_act_bits=self.config['hidden_fc_activation_quantization_bits'],\n",
        "          quantized_weight_bits=self.config['hidden_fc_weight_quantization_bits'],\n",
        "          freeze_params=training_phase_knobs.freeze_hidden_fc_params,\n",
        "          use_pruning_mask=training_phase_knobs.prune_fc_layers))\n",
        "      next_input_dim = hidden_output_dim\n",
        "\n",
        "    self.last_layer = FCLayer(\n",
        "        next_input_dim, 1,\n",
        "        activation=None,\n",
        "        quantize=training_phase_knobs.quantize_final_fc,\n",
        "        quantized_act_bits=0,\n",
        "        quantized_weight_bits=self.config['final_fc_weight_quantization_bits'],\n",
        "        freeze_params=False,\n",
        "        use_pruning_mask=False)\n",
        "\n",
        "  def forward(self, x):    \n",
        "    for i in range(len(self.hidden_layers)):\n",
        "      x = self.hidden_layers[i](x)\n",
        "    x = self.last_layer(x)\n",
        "    return x.squeeze(dim=1)\n",
        "\n",
        "  def randomize_weights(self):\n",
        "    for i in range(len(self.config['hidden_neurons'])):\n",
        "      self.hidden_layers[i].randomize_weights()\n",
        "    self.last_layer.randomize_weights()\n",
        "\n",
        "  def l1_loss(self):\n",
        "    loss = self.last_layer.l1_loss()\n",
        "    # Skip the first hidden fc for regularization.\n",
        "    for i in range(1, len(self.config['hidden_neurons'])):\n",
        "      loss += self.hidden_layers[i].l1_loss()\n",
        "    return loss\n",
        "\n",
        "  def setup_fc_pruning_masks(self):\n",
        "    for i in range(0, len(self.config['hidden_neurons'])):\n",
        "      if i == len(self.config['hidden_neurons']) - 1:\n",
        "        next_layer = self.last_layer\n",
        "      else:\n",
        "        next_layer = self.hidden_layers[i + 1]\n",
        "      sum_next_weights = torch.sum(torch.abs(next_layer.weight), dim=[0])\n",
        "      top_neuron_indices = torch.topk(\n",
        "          sum_next_weights,\n",
        "          self.config['pruned_hidden_neurons'][i]).indices\n",
        "      self.hidden_layers[i].setup_pruning_mask(top_neuron_indices)\n",
        "\n",
        "class BranchNet(nn.Module):\n",
        "  \"\"\"\n",
        "  A Pytorch neural network module class to define BranchNet architecture.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config, training_phase_knobs):\n",
        "    super(BranchNet, self).__init__()\n",
        "\n",
        "    assert lists_have_equal_length(\n",
        "        [config['history_lengths'], config['conv_filters'],\n",
        "         config['conv_widths'], config['pooling_widths']])\n",
        "\n",
        "    self.history_lengths = config['history_lengths']\n",
        "    self.config = config\n",
        "    self.linear_pruning_mask = None\n",
        "    self.quantize_fc = False\n",
        "    self.training_phase_knobs = training_phase_knobs\n",
        "\n",
        "    num_slices = len(self.history_lengths)\n",
        "    self.slices = nn.ModuleList()\n",
        "    concatenated_slices_output_size = 0\n",
        "    for slice_id in range(num_slices):\n",
        "      if config['conv_filters'][slice_id] > 0:\n",
        "        self.slices.append(Slice(config, slice_id,  training_phase_knobs))\n",
        "        concatenated_slices_output_size += self.slices[slice_id].get_output_size()\n",
        "      else:\n",
        "        self.slices.append(nn.ReLU()) #insert dummy module instead of a slice    \n",
        "    self.mlp = BranchNetMLP(self.config, self.training_phase_knobs,\n",
        "                            concatenated_slices_output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #pylint: disable=arguments-differ\n",
        "    #It is expected to change forward() arguments.\n",
        "    #if self.linear_pruning_mask is not None:\n",
        "    #  self.state_dict()['linear.weight'][:] = self.linear.weight * self.linear_pruning_mask\n",
        "    if any(self.config['shifting_pooling']):\n",
        "      global_shift = np.random.randint(max(self.config['pooling_widths']), size=(x.shape[0]))\n",
        "    else:\n",
        "      global_shift = None\n",
        "\n",
        "    slice_outs = []\n",
        "    num_slices = len(self.history_lengths)\n",
        "\n",
        "    for slice_id in range(num_slices):\n",
        "      if self.config['conv_filters'][slice_id] > 0:\n",
        "        x_ = extract_slice_history(x, self.config, global_shift, slice_id)\n",
        "        x_ = self.slices[slice_id](x_)\n",
        "        slice_outs.append(x_)        \n",
        "    x = torch.cat(slice_outs, dim=1)    \n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "  def train(self, mode=True):\n",
        "    super(BranchNet, self).train(mode)\n",
        "    if self.training_phase_knobs.freeze_sumpooling_batchnorm_params:\n",
        "      for slice_id in range(len(self.history_lengths)):\n",
        "        self.slices[slice_id].pooling_batchnorm.eval()\n",
        "\n",
        "  def reinitialize_fc_weights(self):\n",
        "    self.mlp.randomize_weights()\n",
        "\n",
        "  def prune_hidden_fc(self, n):\n",
        "    self.linear_pruning_mask = self.linear.weight.clone().detach().zero_()\n",
        "    selected_indices = torch.topk(abs(self.linear.weight), n, dim=1)\n",
        "    self.linear_pruning_mask.scatter_(1, selected_indices[1], 1)\n",
        "    \n",
        "\n",
        "  def linear_regularization_loss(self):\n",
        "    return torch.norm(self.linear.weight)\n",
        "\n",
        "  def group_lasso_loss_values(self):\n",
        "    \"\"\" Get the loss term for convolution filters group lassos\n",
        "    \"\"\"\n",
        "    lasso_groups = []\n",
        "    num_slices = len(self.history_lengths)\n",
        "\n",
        "    for slice_id in range(num_slices):\n",
        "      conv_weights_squared = self.slices[slice_id].conv.weight.pow(2)\n",
        "      lasso_groups.append(torch.sqrt(conv_weights_squared.sum(dim=[1, 2])))\n",
        "\n",
        "    return lasso_groups\n",
        "\n",
        "  def group_lasso_loss(self):\n",
        "    \"\"\" Get the loss term for convolution filters group lassos\n",
        "    \"\"\"\n",
        "    lasso_groups = []\n",
        "    #linear_weights_squared = self.linear.weight.pow(2)\n",
        "    if len(self.mlp.hidden_layers) > 0:\n",
        "      linear_weights_squared = self.mlp.hidden_layers[0].weight.pow(2)\n",
        "    else:\n",
        "      linear_weights_squared = self.mlp.last_layer.weight.pow(2)\n",
        "    num_slices = len(self.history_lengths)\n",
        "\n",
        "    i = 0\n",
        "    for slice_id in range(num_slices):\n",
        "      # Grouping Convolution Weights.\n",
        "      conv_weights_squared = self.slices[slice_id].conv.weight.pow(2)\n",
        "      lasso_groups.append(conv_weights_squared.sum(dim=[1, 2]))\n",
        "      lasso_groups.append(self.slices[slice_id].embedding_table.weight.pow(2).sum(dim=[1]))\n",
        "\n",
        "      # Grouping Fully-connected Weights.\n",
        "      slice_output_size = self.slices[slice_id].get_output_size()\n",
        "      num_filters = self.config['conv_filters'][slice_id]\n",
        "\n",
        "      slice_linear_weights_squared = (\n",
        "          linear_weights_squared[:, i:i+slice_output_size])\n",
        "      i += slice_output_size\n",
        "\n",
        "      slice_linear_weights_squared = slice_linear_weights_squared.view(\n",
        "          -1, num_filters, slice_output_size // num_filters)\n",
        "      lasso_groups.append(slice_linear_weights_squared.sum(dim=[0, 2]))\n",
        "\n",
        "    return torch.sum(torch.sqrt(torch.cat(lasso_groups, dim=0)))\n",
        "\n",
        "  def fc_weights_l1_loss(self):\n",
        "    return self.mlp.l1_loss()\n",
        "\n",
        "  def copy_from_other_model(self, other_model):\n",
        "    for key in self.state_dict():\n",
        "      if key in other_model.state_dict():\n",
        "        if len(other_model.state_dict()[key].shape) > 0:\n",
        "          if (self.state_dict()[key].shape\n",
        "              == other_model.state_dict()[key].shape):\n",
        "            self.state_dict()[key][:] = other_model.state_dict()[key]\n",
        "          else:\n",
        "            print('Warning: did not copy', key)\n",
        "    self.copy_masks(other_model)\n",
        "\n",
        "  def setup_fc_pruning_masks(self):\n",
        "    self.mlp.setup_fc_pruning_masks()\n",
        "\n",
        "  def quantize_luts(self, x, conv_activation_type, conv_quantization_bits):\n",
        "    quantize = Quantize.apply\n",
        "    if conv_activation_type == 'relu':\n",
        "      act = nn.ReLU()\n",
        "      assert conv_quantization_bits == 0\n",
        "      x = act(x)\n",
        "    elif conv_activation_type == 'sigmoid':\n",
        "      act = nn.Sigmoid()\n",
        "      x = act(x)\n",
        "      if conv_quantization_bits > 0:\n",
        "        x = quantize(x, True, conv_quantization_bits)\n",
        "    elif conv_activation_type == 'tanh':\n",
        "      act = nn.Tanh()\n",
        "      x = act(x)\n",
        "      if conv_quantization_bits > 0:\n",
        "        x = quantize(x, False, conv_quantization_bits)\n",
        "    return x\n",
        "\n",
        "  def load_convolution_luts(self, trained_branchnet):\n",
        "    assert self.training_phase_knobs.lut_convolution is True\n",
        "    assert trained_branchnet.training_phase_knobs.lut_convolution is False\n",
        "\n",
        "    conv_filters = self.config['conv_filters']\n",
        "    conv_widths = self.config['conv_widths']\n",
        "    conv_activation_type = self.config['conv_activation']\n",
        "    conv_quantization_bits = self.config['conv_quantization_bits']\n",
        "    self.copy_from_other_model(trained_branchnet)\n",
        "\n",
        "    if self.config['combined_hash_convolution']:\n",
        "      for slice_id in range(len(conv_filters)):\n",
        "        orig_embedding = trained_branchnet.state_dict()[\n",
        "            'slices.{}.combined_embedding_table.weight'.format(slice_id)]\n",
        "        conv_weight = trained_branchnet.state_dict()[\n",
        "            'slices.{}.combined_conv.weight'.format(slice_id)]\n",
        "        conv_bias = trained_branchnet.state_dict()[\n",
        "            'slices.{}.combined_conv.bias'.format(slice_id)]\n",
        "        batchnorm_weight = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.weight'.format(slice_id)]\n",
        "        batchnorm_bias = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.bias'.format(slice_id)]\n",
        "        batchnorm_mean = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.running_mean'.format(slice_id)]\n",
        "        batchnorm_var = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.running_var'.format(slice_id)]\n",
        "\n",
        "        new_embedding = self.state_dict()[\n",
        "            'slices.{}.combined_lookup_table.weight'.format(slice_id)]\n",
        "\n",
        "        conv_weights_transposed = conv_weight[:, :, 0].transpose(0, 1)\n",
        "        new_embedding[:] = torch.matmul(orig_embedding, conv_weights_transposed)\n",
        "        new_embedding += conv_bias.view(1, conv_filters[slice_id])\n",
        "        new_embedding -= batchnorm_mean.view(1, conv_filters[slice_id])\n",
        "        new_embedding /= torch.sqrt(\n",
        "            batchnorm_var.view(1, conv_filters[slice_id]) + 1e-5)\n",
        "        new_embedding *= batchnorm_weight.view(1, conv_filters[slice_id])\n",
        "        new_embedding += batchnorm_bias.view(1, conv_filters[slice_id])\n",
        "\n",
        "        new_embedding[:] = self.quantize_luts(\n",
        "            new_embedding, conv_activation_type, conv_quantization_bits)\n",
        "        final_luts = new_embedding\n",
        "\n",
        "        if conv_quantization_bits > 0:\n",
        "          max_val = 1\n",
        "          if conv_activation_type in ['sigmoid' or 'cross_channel_sigmoid_binarize']:\n",
        "            min_val = 0\n",
        "            num_slices = (2 ** conv_quantization_bits - 1)\n",
        "          elif conv_activation_type == 'tanh':\n",
        "            min_val = -1\n",
        "            num_slices = max(1, 2 ** conv_quantization_bits - 2)\n",
        "          else:\n",
        "            assert False\n",
        "\n",
        "          step = (max_val - min_val) / num_slices\n",
        "          bin_boundaries = np.arange(min_val, max_val, step) + (step/2)\n",
        "          bin_values = np.concatenate([np.arange(min_val, max_val, step), np.array([max_val])])\n",
        "          digitized_filters = np.digitize(final_luts.cpu().numpy(), bin_boundaries)\n",
        "          for bin_id in range(len(bin_boundaries) + 1):\n",
        "            print('Number of {}: {}'.format(bin_values[bin_id], np.sum(digitized_filters == bin_id)))\n",
        "        \n",
        "    else:\n",
        "      for slice_id in range(len(conv_filters)):\n",
        "        orig_embedding = trained_branchnet.state_dict()[\n",
        "            'slices.{}.embedding_table.weight'.format(slice_id)]\n",
        "        conv_weight = trained_branchnet.state_dict()[\n",
        "            'slices.{}.conv.weight'.format(slice_id)]\n",
        "        conv_bias = trained_branchnet.state_dict()[\n",
        "            'slices.{}.conv.bias'.format(slice_id)]\n",
        "        batchnorm_weight = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.weight'.format(slice_id)]\n",
        "        batchnorm_bias = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.bias'.format(slice_id)]\n",
        "        batchnorm_mean = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.running_mean'.format(slice_id)]\n",
        "        batchnorm_var = trained_branchnet.state_dict()[\n",
        "            'slices.{}.batchnorm.running_var'.format(slice_id)]\n",
        "        \n",
        "        list_new_embeddings = []\n",
        "        for conv_pos in range(conv_widths[slice_id]):\n",
        "          new_embedding = self.state_dict()[\n",
        "              'slices.{}.lookup_tables.{}.weight'.format(slice_id, conv_pos)]\n",
        "          conv_pos_weights = conv_weight[ :, :, conv_pos]\n",
        "          conv_pos_weights = conv_pos_weights.transpose(0, 1)\n",
        "          new_embedding[:] = torch.matmul(orig_embedding, conv_pos_weights)\n",
        "          new_embedding[:] = new_embedding + (\n",
        "              conv_bias.view(1, conv_filters[slice_id]) / conv_widths[slice_id])\n",
        "          new_embedding[:] = new_embedding - (\n",
        "              batchnorm_mean.view(1, conv_filters[slice_id]) / conv_widths[slice_id])\n",
        "          new_embedding[:] = new_embedding * batchnorm_weight.view(1, conv_filters[slice_id])\n",
        "          new_embedding[:] = new_embedding / torch.sqrt(\n",
        "              batchnorm_var.view(1, conv_filters[slice_id]) + 1e-5)\n",
        "          new_embedding += batchnorm_bias.view(\n",
        "              1, conv_filters[slice_id]) / conv_widths[slice_id]\n",
        "          list_new_embeddings.append(new_embedding)\n",
        "\n",
        "  def setup_conv_pruning_masks(self, useful_channels):\n",
        "    print('Useful Channels:', useful_channels)\n",
        "    for slice_id, useful_channels_for_slice in enumerate(useful_channels):\n",
        "      self.slices[slice_id].setup_pruning_mask(useful_channels_for_slice)\n",
        "  \n",
        "  def copy_masks(self, other):\n",
        "    if (self.training_phase_knobs.prune_filters\n",
        "        and other.training_phase_knobs.prune_filters):\n",
        "      num_slices = len(self.config['conv_filters'])\n",
        "      for slice_id in range(num_slices):\n",
        "        self.slices[slice_id].pruning_mask = other.slices[slice_id].pruning_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import  torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BranchHistoryDataset(Dataset):\n",
        "    def __init__(self, csv_path, history_lengths):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        self.max_hist = max(history_lengths)\n",
        "        self.histories = []\n",
        "        self.targets   = torch.tensor(df[\"taken\"].values, dtype=torch.float32)\n",
        "\n",
        "        for hist_str in df[\"history\"].fillna(\"\").values:\n",
        "            bits   = [int(b) for b in hist_str.split(\",\") if b != \"\"]\n",
        "            tokens = bits[-self.max_hist:]                          # truncate\n",
        "            tokens = [0]*(self.max_hist-len(tokens)) + tokens       # left-pad\n",
        "            self.histories.append(torch.tensor(tokens, dtype=torch.long))\n",
        "\n",
        "    def __len__(self):  return len(self.targets)\n",
        "    def __getitem__(self, i):  return self.histories[i], self.targets[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open(\"/home/gkapakos/Desktop/ECE/10th_Semester/Architecture_of_Parallel_Systems/Project/BranchPredictionAI/KladosNet/branchnet/configs/mini_250.yaml\") as fh:          # â† the file you uploaded\n",
        "    cfg = yaml.safe_load(fh)          # cfg is now a Python dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_phase_knobs = BranchNetTrainingPhaseKnobs()\n",
        "\n",
        "model = BranchNet(cfg, train_phase_knobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "dataloader = BranchHistoryDataset(\"/home/gkapakos/Desktop/ECE/10th_Semester/Architecture_of_Parallel_Systems/Project/BranchPredictionAI/dataset.csv\", cfg['history_lengths'])\n",
        "\n",
        "train_ratio = 0.8                       # 80 % train, 20 % val\n",
        "train_len   = int(train_ratio * len(dataloader))\n",
        "val_len     = len(dataloader) - train_len\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    dataloader,\n",
        "    lengths=[train_len, val_len],\n",
        "    generator=torch.Generator().manual_seed(42)   # fix the seed once\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True,  num_workers=4)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŒŸ Model parameters: 0.01 M\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_65884/4090792369.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler     = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
            "/tmp/ipykernel_65884/4090792369.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
            "/tmp/ipykernel_65884/4090792369.py:56: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 01 â”‚ train loss 0.0005  acc 100.00% â”‚ val loss 0.0001  acc 100.00%\n",
            "   â†³ ðŸ… new best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_65884/4090792369.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m     33\u001b[0m     loss   \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     37\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train_branchnet_minimal.py  (excerpt)\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score          # pip install scikit-learn\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "VAL_RATIO  = 0.2\n",
        "EPOCHS     = 10\n",
        "LR         = 3e-4\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "criterion  = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler  = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "scaler     = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
        "\n",
        "print(f\"ðŸŒŸ Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f} M\")\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.train()\n",
        "    train_loss_sum, train_samples = 0.0, 0\n",
        "    train_preds,  train_labels    = [], []\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "            logits = model(X)\n",
        "            loss   = criterion(logits, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # bookkeeping\n",
        "        train_loss_sum += loss.item() * X.size(0)\n",
        "        train_samples  += X.size(0)\n",
        "\n",
        "        train_preds.append((logits > 0).cpu())   # logits>0 == prob>0.5\n",
        "        train_labels.append(y.cpu())\n",
        "\n",
        "    scheduler.step()\n",
        "    train_loss = train_loss_sum / train_samples\n",
        "    train_acc  = accuracy_score(torch.cat(train_labels),\n",
        "                                torch.cat(train_preds))\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VALIDATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.eval()\n",
        "    val_loss_sum, val_samples = 0.0, 0\n",
        "    val_preds,  val_labels    = [], []\n",
        "\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            logits   = model(X)\n",
        "            val_loss = criterion(logits, y)\n",
        "\n",
        "            val_loss_sum += val_loss.item() * X.size(0)\n",
        "            val_samples  += X.size(0)\n",
        "\n",
        "            val_preds.append((logits > 0).cpu())\n",
        "            val_labels.append(y.cpu())\n",
        "\n",
        "    val_loss = val_loss_sum / val_samples\n",
        "    val_acc  = accuracy_score(torch.cat(val_labels),\n",
        "                              torch.cat(val_preds))\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LOG / CKPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(f\"epoch {epoch:02d} â”‚ \"\n",
        "          f\"train loss {train_loss:.4f}  acc {train_acc*100:5.2f}% â”‚ \"\n",
        "          f\"val loss {val_loss:.4f}  acc {val_acc*100:5.2f}%\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"branchnet_best.pt\")\n",
        "        print(\"   â†³ ðŸ… new best model saved\")\n",
        "\n",
        "print(f\"âœ… finished â€“ best val loss {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ÎšÎ»Î±Î´Î¿Ï‚ Net\n",
        "# \"\"\"\n",
        "# Definition of a BranchNet model in Pytorch\n",
        "# \"\"\"\n",
        "\n",
        "# import math\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def lists_have_equal_length(list_of_lists):\n",
        "#   \"\"\"helper function to check that the length of lists are equals\"\"\"\n",
        "#   set_of_lengths = set(map(len, list_of_lists))\n",
        "#   return len(set_of_lengths) <= 1\n",
        "\n",
        "\n",
        "# # Extraction here happens from the configs folder where all the yaml files reside\n",
        "# def extract_slice_history(x, config, global_shift, slice_id):\n",
        "#   \"\"\"Extract a portion of history for a slice.\"\"\"\n",
        "\n",
        "#   total_history_size = x.shape[1]\n",
        "#   slice_size = config['history_lengths'][slice_id]\n",
        "#   pooling_width = config['pooling_widths'][slice_id]\n",
        "#   assert slice_size <= total_history_size\n",
        "\n",
        "#   if config['shifting_pooling'][slice_id]:\n",
        "#     slice_shift = global_shift % pooling_width\n",
        "#     inputs = []\n",
        "#     for i in range(x.shape[0]):\n",
        "#       slice_end = total_history_size - slice_shift[i]\n",
        "#       slice_start = slice_end - slice_size\n",
        "#       inputs.append(x[i, slice_start:slice_end])\n",
        "#     return torch.stack(inputs)\n",
        "#   else:\n",
        "#     return x[:, -slice_size:]\n",
        "\n",
        "\n",
        "# class Slice(nn.Module):\n",
        "#   \"\"\"A Pytorch neural network module class to define a BranchNet slice\n",
        "#     corresponding to some portion of the history.\n",
        "#   \"\"\"\n",
        "\n",
        "#   def __init__(self, config, slice_id):\n",
        "#     \"\"\"Creates all the layers and computes the expected output size.\n",
        "#     \"\"\"\n",
        "#     super(Slice, self).__init__()\n",
        "#     history_length = config['history_lengths'][slice_id]\n",
        "#     conv_filters = config['conv_filters'][slice_id]\n",
        "#     conv_width = config['conv_widths'][slice_id]\n",
        "#     pooling_width = config['pooling_widths'][slice_id]\n",
        "#     embedding_dims = config['embedding_dims']\n",
        "#     use_Transformer_encoder = config['use_Transformer_encoder']\n",
        "#     pc_hash_bits = config['pc_hash_bits']\n",
        "#     hash_dir_with_pc = config['hash_dir_with_pc']\n",
        "\n",
        "#     # remember slice configuration\n",
        "#     self.config = config\n",
        "#     self.slice_id = slice_id\n",
        "\n",
        "#     # Declare all the neural network layers\n",
        "#     index_width = pc_hash_bits if hash_dir_with_pc else (pc_hash_bits + 1)\n",
        "#     if config['combined_hash_convolution']:\n",
        "#       assert not hash_dir_with_pc\n",
        "#       self.build_hashing_metadata()\n",
        "#       self.combined_embedding_table = nn.Embedding(\n",
        "#           2 ** config['combined_hash_convolution_width'],\n",
        "#           embedding_dims)\n",
        "#       self.combined_conv = nn.Conv1d(embedding_dims, conv_filters, 1)\n",
        "#       self.batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "#     else:\n",
        "#       self.embedding_table = nn.Embedding(2 ** index_width, embedding_dims)\n",
        "#       if(use_Transformer_encoder):\n",
        "#         self.Transformer_encoder = nn.TransformerEncoderLayer(d_model=embedding_dims, nhead=8, dim_feedforward=512, dropout=0.3)\n",
        "#       self.conv = nn.Conv1d(embedding_dims, conv_filters, conv_width)\n",
        "#       self.batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "\n",
        "#     self.pooling = nn.AvgPool1d(pooling_width, padding=0)\n",
        "#     self.pooling_batchnorm = nn.BatchNorm1d(conv_filters)\n",
        "\n",
        "\n",
        "#     # compute the slice output size\n",
        "#     if pooling_width == -1 or (config['shifting_pooling'][slice_id]\n",
        "#                                and config['sum_all_if_shifting_pool']):\n",
        "#       pooling_output_size = 1\n",
        "#     elif pooling_width > 0: \n",
        "#       conv_output_size = (history_length - conv_width + 1)\n",
        "#       pooling_output_size = conv_output_size // pooling_width\n",
        "#     else:\n",
        "#       pooling_output_size = (history_length - conv_width + 1)\n",
        "#     self.total_output_size = pooling_output_size * conv_filters\n",
        "#     if(self.config['use_lstm']):\n",
        "#       self.lstm = nn.LSTM(\n",
        "#         input_size=self.config['lstm_inp_dim'],\n",
        "#         hidden_size=self.config['lstm_hidden_size'],\n",
        "#         bidirectional = self.config['bidirectional'],\n",
        "#         batch_first=True\n",
        "#       )\n",
        "\n",
        "#   def build_hashing_metadata(self):\n",
        "#     num_input_bits = ((self.config['pc_hash_bits'] + 1) *\n",
        "#                       max(self.config['conv_widths']))\n",
        "#     num_output_bits = self.config['combined_hash_convolution_width']\n",
        "\n",
        "#     assert num_output_bits < 32\n",
        "#     self.hash_metadata = nn.Parameter(torch.randint(\n",
        "#         0, 2 ** num_output_bits, size=[num_input_bits], dtype=torch.int64), requires_grad=False)\n",
        "\n",
        "#   def hash_using_metadata(self, x, conv_width):\n",
        "#     batch_size = x.shape[0]\n",
        "#     available_history = x.shape[1]\n",
        "#     output_history = available_history + 1 - conv_width\n",
        "#     bits_per_conv_pos = self.config['pc_hash_bits'] + 1\n",
        "#     zero_tensor = torch.zeros(1,\n",
        "#                       dtype=torch.int64, device=x.device)\n",
        "#     out = torch.zeros(batch_size, output_history,\n",
        "#                       dtype=torch.int64, device=x.device)\n",
        "\n",
        "#     for conv_pos in range(conv_width):\n",
        "#       history_slice = x[:, available_history - conv_pos - output_history: available_history - conv_pos]\n",
        "#       for bit in range(bits_per_conv_pos):\n",
        "#         metadata_idx = conv_pos * bits_per_conv_pos + bit\n",
        "#         xor_pattern = self.hash_metadata[metadata_idx: metadata_idx + 1]\n",
        "#         out = out ^ torch.where((history_slice >> bit) & 1 == 1, xor_pattern, zero_tensor)\n",
        "    \n",
        "#     return out\n",
        "\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     history_length = self.config['history_lengths'][self.slice_id]\n",
        "#     conv_filters = self.config['conv_filters'][self.slice_id]\n",
        "#     conv_width = self.config['conv_widths'][self.slice_id]\n",
        "#     pooling_width = self.config['pooling_widths'][self.slice_id]\n",
        "\n",
        "#     # convolution and batch norm layers\n",
        "#     if self.config['combined_hash_convolution']:\n",
        "#       x = self.hash_using_metadata(x, conv_width)\n",
        "#       x = self.combined_embedding_table(x)\n",
        "#       x = torch.transpose(x, 1, 2)\n",
        "#       x = self.combined_conv(x)\n",
        "#       x = self.batchnorm(x)\n",
        "#       x = self.convolution_activation(x)\n",
        "#     else:\n",
        "#       x = self.embedding_table(x)\n",
        "#       if (self.config['use_Transformer_encoder']):          \n",
        "#         x = self.Transformer_encoder(x)        \n",
        "#       x = torch.transpose(x, 1, 2)                \n",
        "#       x = self.conv(x)        \n",
        "#       x = self.batchnorm(x)\n",
        "#       x = self.convolution_activation(x)\n",
        "\n",
        "#     # pooling\n",
        "#     if pooling_width == -1 or (self.config['shifting_pooling'][self.slice_id]\n",
        "#                                and self.config['sum_all_if_shifting_pool']):\n",
        "#       x = torch.sum(x, 2, keepdim=True)\n",
        "#     elif pooling_width > 0:\n",
        "#       x = self.pooling(x) * pooling_width    \n",
        "#     x = self.sumpooling_activation(x)\n",
        "#     if(self.config['use_lstm']):\n",
        "#       x = x.permute(0, 2, 1)\n",
        "#       _ , (x , _ ) = self.lstm(x)\n",
        "#       x = x.permute(0, 2, 1)\n",
        "#       return x.reshape(-1, self.total_output_size)\n",
        "#     else:\n",
        "#       return x.view(-1, self.total_output_size)\n",
        "\n",
        "#   def get_output_size(self):\n",
        "#     \"\"\"Returns the expected output size for the slice\n",
        "#     \"\"\"\n",
        "#     return self.total_output_size\n",
        "\n",
        "#   def convolution_activation(self, x):\n",
        "#     \"\"\"Returns post- and pre- quantization activations.\"\"\"\n",
        "#     relu_act = nn.ReLU(inplace=True)\n",
        "#     sigmoid_act = nn.Sigmoid()\n",
        "#     tanh_act = nn.Tanh()\n",
        "\n",
        "#     conv_activation_type = self.config['conv_activation']\n",
        "\n",
        "#     if conv_activation_type == 'relu':\n",
        "#       x = relu_act(x)\n",
        "#       return x\n",
        "#     if conv_activation_type == 'sigmoid':\n",
        "#       x = sigmoid_act(x)\n",
        "#       return x\n",
        "#     if conv_activation_type == 'tanh':\n",
        "#       x = tanh_act(x)\n",
        "#       return x\n",
        "    \n",
        "#     assert False\n",
        "\n",
        "#   def sumpooling_activation(self, x):\n",
        "\n",
        "#     tanh_act = nn.Tanh()\n",
        "#     hardtanh_act = nn.Hardtanh()\n",
        "#     sigmoid_act = nn.Tanh()\n",
        "#     hardsigmoid_act = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
        "\n",
        "#     activation = self.config['sumpooling_activation']\n",
        "\n",
        "#     if activation == 'none':\n",
        "#       return x\n",
        "#     if activation == 'bn_only':\n",
        "#       return self.pooling_batchnorm(x)\n",
        "#     if activation == 'tanh':\n",
        "#       x = tanh_act(self.pooling_batchnorm(x))\n",
        "#       return x\n",
        "#     if activation == 'hardtanh':\n",
        "#       x = hardtanh_act(self.pooling_batchnorm(x))\n",
        "#       return x\n",
        "#     if activation == 'sigmoid':\n",
        "#       x = sigmoid_act(self.pooling_batchnorm(x))\n",
        "#       return x\n",
        "#     if activation == 'hardsigmoid':\n",
        "#       x = hardsigmoid_act(self.pooling_batchnorm(x))\n",
        "#       return x\n",
        "\n",
        "#     assert False\n",
        "\n",
        "\n",
        "# class FCLayer(nn.Module):\n",
        "#   def __init__(self, input_dim, output_dim, activation):\n",
        "#     super(FCLayer, self).__init__()\n",
        "#     self.activation = activation\n",
        "\n",
        "#     self.weight = nn.Parameter(torch.empty(output_dim, input_dim))\n",
        "#     self.bias = nn.Parameter(torch.empty(output_dim))\n",
        "#     if activation is not None:\n",
        "#       self.batchnorm = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "\n",
        "#     self.randomize_weights()\n",
        "\n",
        "#   def forward(self, x):\n",
        "   \n",
        "#     weight = self.weight\n",
        "\n",
        "#     x = nn.functional.linear(x, weight, bias=self.bias)\n",
        "#     if self.activation is not None:\n",
        "#       x = self.activation_layer(x)\n",
        "#     return x\n",
        "\n",
        "#   def activation_layer(self, x):\n",
        "#     x = self.batchnorm(x)\n",
        "\n",
        "#     relu_act = nn.ReLU(inplace=True)\n",
        "#     sigmoid_act = nn.Sigmoid()\n",
        "#     tanh_act = nn.Tanh()\n",
        "#     hardtanh_act = nn.Hardtanh()\n",
        "\n",
        "#     if self.activation == 'relu':\n",
        "#       x = relu_act(x)\n",
        "#     elif self.activation == 'sigmoid':\n",
        "#       x = sigmoid_act(x)\n",
        "#     elif self.activation == 'tanh':\n",
        "#       x = tanh_act(x)\n",
        "#     elif self.activation == 'hardtanh':\n",
        "#       x = hardtanh_act(x)\n",
        "#     else:\n",
        "#       assert False\n",
        "\n",
        "#     return x\n",
        "\n",
        "#   def randomize_weights(self):\n",
        "#     output_dim = self.weight.shape[0]\n",
        "#     input_dim = self.weight.shape[1]\n",
        "#     glorot_init_bound = math.sqrt(2. / (input_dim + output_dim))\n",
        "#     self.weight.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "#     self.bias.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "\n",
        "#   def l1_loss(self):\n",
        "#     return torch.sum(torch.abs(self.weight))\n",
        "\n",
        "\n",
        "\n",
        "# class BranchNetMLP(nn.Module):\n",
        "#   def __init__(self, config, flattened_input_dim):\n",
        "#     super(BranchNetMLP, self).__init__()\n",
        "#     self.config = config\n",
        "#     self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "#     next_input_dim = flattened_input_dim\n",
        "#     for hidden_output_dim in self.config['hidden_neurons']:\n",
        "#       assert hidden_output_dim > 0\n",
        "#       self.hidden_layers.append(FCLayer(\n",
        "#           next_input_dim, hidden_output_dim,\n",
        "#           activation=self.config['hidden_fc_activation']))\n",
        "#       next_input_dim = hidden_output_dim\n",
        "\n",
        "#     self.last_layer = FCLayer(\n",
        "#         next_input_dim, 1,\n",
        "#         activation=None)\n",
        "\n",
        "#   def forward(self, x):    \n",
        "#     for i in range(len(self.hidden_layers)):\n",
        "#       x = self.hidden_layers[i](x)\n",
        "#     x = self.last_layer(x)\n",
        "#     return x.squeeze(dim=1)\n",
        "\n",
        "#   def randomize_weights(self):\n",
        "#     for i in range(len(self.config['hidden_neurons'])):\n",
        "#       self.hidden_layers[i].randomize_weights()\n",
        "#     self.last_layer.randomize_weights()\n",
        "\n",
        "#   def l1_loss(self):\n",
        "#     loss = self.last_layer.l1_loss()\n",
        "#     # Skip the first hidden fc for regularization.\n",
        "#     for i in range(1, len(self.config['hidden_neurons'])):\n",
        "#       loss += self.hidden_layers[i].l1_loss()\n",
        "#     return loss\n",
        "\n",
        "# class BranchNet(nn.Module):\n",
        "#   \"\"\"\n",
        "#   A Pytorch neural network module class to define BranchNet architecture.\n",
        "#   \"\"\"\n",
        "\n",
        "#   def __init__(self, config):\n",
        "#     super(BranchNet, self).__init__()\n",
        "\n",
        "#     assert lists_have_equal_length(\n",
        "#         [config['history_lengths'], config['conv_filters'],\n",
        "#          config['conv_widths'], config['pooling_widths']])\n",
        "\n",
        "#     self.history_lengths = config['history_lengths']\n",
        "#     self.config = config\n",
        "\n",
        "#     num_slices = len(self.history_lengths)\n",
        "#     self.slices = nn.ModuleList()\n",
        "#     concatenated_slices_output_size = 0\n",
        "#     for slice_id in range(num_slices):\n",
        "#       if config['conv_filters'][slice_id] > 0:\n",
        "#         self.slices.append(Slice(config, slice_id))\n",
        "#         concatenated_slices_output_size += self.slices[slice_id].get_output_size()\n",
        "#       else:\n",
        "#         self.slices.append(nn.ReLU()) #insert dummy module instead of a slice    \n",
        "#     self.mlp = BranchNetMLP(self.config,\n",
        "#                             concatenated_slices_output_size)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     #pylint: disable=arguments-differ\n",
        "#     #It is expected to change forward() arguments.\n",
        "#     if any(self.config['shifting_pooling']):\n",
        "#       global_shift = np.random.randint(max(self.config['pooling_widths']), size=(x.shape[0]))\n",
        "#     else:\n",
        "#       global_shift = None\n",
        "\n",
        "#     slice_outs = []\n",
        "#     num_slices = len(self.history_lengths)\n",
        "\n",
        "#     for slice_id in range(num_slices):\n",
        "#       if self.config['conv_filters'][slice_id] > 0:\n",
        "#         x_ = extract_slice_history(x, self.config, global_shift, slice_id)\n",
        "#         x_ = self.slices[slice_id](x_)\n",
        "#         slice_outs.append(x_)        \n",
        "#     x = torch.cat(slice_outs, dim=1)    \n",
        "#     x = self.mlp(x)\n",
        "#     return x\n",
        "\n",
        "#   def train(self, mode=True):\n",
        "#     super(BranchNet, self).train(mode)\n",
        "\n",
        "#   def reinitialize_fc_weights(self):\n",
        "#     self.mlp.randomize_weights()\n",
        "\n",
        "#   def linear_regularization_loss(self):\n",
        "#     return torch.norm(self.linear.weight)\n",
        "\n",
        "#   def group_lasso_loss_values(self):\n",
        "#     \"\"\" Get the loss term for convolution filters group lassos\n",
        "#     \"\"\"\n",
        "#     lasso_groups = []\n",
        "#     num_slices = len(self.history_lengths)\n",
        "\n",
        "#     for slice_id in range(num_slices):\n",
        "#       conv_weights_squared = self.slices[slice_id].conv.weight.pow(2)\n",
        "#       lasso_groups.append(torch.sqrt(conv_weights_squared.sum(dim=[1, 2])))\n",
        "\n",
        "#     return lasso_groups\n",
        "\n",
        "#   def group_lasso_loss(self):\n",
        "#     \"\"\" Get the loss term for convolution filters group lassos\n",
        "#     \"\"\"\n",
        "#     lasso_groups = []\n",
        "#     if len(self.mlp.hidden_layers) > 0:\n",
        "#       linear_weights_squared = self.mlp.hidden_layers[0].weight.pow(2)\n",
        "#     else:\n",
        "#       linear_weights_squared = self.mlp.last_layer.weight.pow(2)\n",
        "#     num_slices = len(self.history_lengths)\n",
        "\n",
        "#     i = 0\n",
        "#     for slice_id in range(num_slices):\n",
        "#       # Grouping Convolution Weights.\n",
        "#       conv_weights_squared = self.slices[slice_id].conv.weight.pow(2)\n",
        "#       lasso_groups.append(conv_weights_squared.sum(dim=[1, 2]))\n",
        "#       lasso_groups.append(self.slices[slice_id].embedding_table.weight.pow(2).sum(dim=[1]))\n",
        "\n",
        "#       # Grouping Fully-connected Weights.\n",
        "#       slice_output_size = self.slices[slice_id].get_output_size()\n",
        "#       num_filters = self.config['conv_filters'][slice_id]\n",
        "\n",
        "#       slice_linear_weights_squared = (\n",
        "#           linear_weights_squared[:, i:i+slice_output_size])\n",
        "#       i += slice_output_size\n",
        "\n",
        "#       slice_linear_weights_squared = slice_linear_weights_squared.view(\n",
        "#           -1, num_filters, slice_output_size // num_filters)\n",
        "#       lasso_groups.append(slice_linear_weights_squared.sum(dim=[0, 2]))\n",
        "\n",
        "#     return torch.sum(torch.sqrt(torch.cat(lasso_groups, dim=0)))\n",
        "\n",
        "#   def fc_weights_l1_loss(self):\n",
        "#     return self.mlp.l1_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÎšÎ»Î±Î´Î¿Ï‚ Net\n",
        "\"\"\"\n",
        "Definition of a BranchNet model in Pytorch\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "################## BranchNet Architecture #####################\n",
        "\n",
        "# Size of global history used in each chunk\n",
        "history_lengths = [44, 92, 182]\n",
        "\n",
        "# Number of convolution filters in each chunk\n",
        "conv_filters = [2, 2, 2]\n",
        "\n",
        "# The width of the convolution filter of each chunk\n",
        "conv_widths = [3, 3, 3]\n",
        "\n",
        "# The width of the pooling layer of each chunk\n",
        "pooling_widths = [7, 15, 30]\n",
        "\n",
        "# Set to True to simulate the effect of smaller inference engine buffers by\n",
        "# randomly shifting the pooling windows\n",
        "shifting_pooling = [False, False, False]\n",
        "\n",
        "\n",
        "def lists_have_equal_length(list_of_lists):\n",
        "  \"\"\"helper function to check that the length of lists are equals\"\"\"\n",
        "  set_of_lengths = set(map(len, list_of_lists))\n",
        "  return len(set_of_lengths) <= 1\n",
        "\n",
        "\n",
        "# Extraction here happens from the configs folder where all the yaml files reside\n",
        "def extract_slice_history(x, global_shift, slice_id):\n",
        "  \"\"\"Extract a portion of history for a slice.\"\"\"\n",
        "\n",
        "  total_history_size = x.shape[1]\n",
        "  slice_size = history_lengths[slice_id]\n",
        "  pooling_width = pooling_widths[slice_id]\n",
        "  assert slice_size <= total_history_size\n",
        "\n",
        "  if shifting_pooling[slice_id]:\n",
        "    slice_shift = global_shift % pooling_width\n",
        "    inputs = []\n",
        "    for i in range(x.shape[0]):\n",
        "      slice_end = total_history_size - slice_shift[i]\n",
        "      slice_start = slice_end - slice_size\n",
        "      inputs.append(x[i, slice_start:slice_end])\n",
        "    return torch.stack(inputs)\n",
        "  else:\n",
        "    return x[:, -slice_size:]\n",
        "\n",
        "\n",
        "class Slice(nn.Module):\n",
        "  \"\"\"A Pytorch neural network module class to define a BranchNet slice\n",
        "    corresponding to some portion of the history.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, slice_id):\n",
        "    \"\"\"Creates all the layers and computes the expected output size.\n",
        "    \"\"\"\n",
        "    super(Slice, self).__init__()\n",
        "    history_length = history_lengths[slice_id]\n",
        "    conv_filter = conv_filters[slice_id]\n",
        "    conv_width = conv_widths[slice_id]\n",
        "    pooling_width = pooling_widths[slice_id]\n",
        "    embedding_dims = 32\n",
        "\n",
        "    # remember slice configuration\n",
        "    self.slice_id = slice_id\n",
        "\n",
        "    # Declare all the neural network layers\n",
        "    self.build_hashing_metadata()\n",
        "    self.combined_embedding_table = nn.Embedding(2 ** 7, embedding_dims)\n",
        "    self.combined_conv = nn.Conv1d(embedding_dims, conv_filter, 1)\n",
        "    self.batchnorm = nn.BatchNorm1d(conv_filter)\n",
        "\n",
        "    self.pooling = nn.AvgPool1d(pooling_width, padding=0)\n",
        "    self.pooling_batchnorm = nn.BatchNorm1d(conv_filter)\n",
        "\n",
        "\n",
        "    # compute the slice output size\n",
        "    if pooling_width == -1:\n",
        "      pooling_output_size = 1\n",
        "    elif pooling_width > 0: \n",
        "      conv_output_size = (history_length - conv_width + 1)\n",
        "      pooling_output_size = conv_output_size // pooling_width\n",
        "    else:\n",
        "      pooling_output_size = (history_length - conv_width + 1)\n",
        "    self.total_output_size = pooling_output_size * conv_filter\n",
        "    # if(self.config['use_lstm']):\n",
        "    #   self.lstm = nn.LSTM(\n",
        "    #     input_size=self.config['lstm_inp_dim'],\n",
        "    #     hidden_size=self.config['lstm_hidden_size'],\n",
        "    #     bidirectional = self.config['bidirectional'],\n",
        "    #     batch_first=True\n",
        "    #   )\n",
        "\n",
        "  def build_hashing_metadata(self):\n",
        "    num_input_bits = ((7) *\n",
        "                      max(conv_widths))\n",
        "    num_output_bits = 7\n",
        "\n",
        "    assert num_output_bits < 32\n",
        "    self.hash_metadata = nn.Parameter(torch.randint(\n",
        "        0, 2 ** num_output_bits, size=[num_input_bits], dtype=torch.int64), requires_grad=False)\n",
        "\n",
        "  def hash_using_metadata(self, x, conv_width):\n",
        "    batch_size = x.shape[0]\n",
        "    available_history = x.shape[1]\n",
        "    output_history = available_history + 1 - conv_width\n",
        "    bits_per_conv_pos = 6 + 1\n",
        "    zero_tensor = torch.zeros(1,\n",
        "                      dtype=torch.int64, device=x.device)\n",
        "    out = torch.zeros(batch_size, output_history,\n",
        "                      dtype=torch.int64, device=x.device)\n",
        "\n",
        "    for conv_pos in range(conv_width):\n",
        "      history_slice = x[:, available_history - conv_pos - output_history: available_history - conv_pos]\n",
        "      for bit in range(bits_per_conv_pos):\n",
        "        metadata_idx = conv_pos * bits_per_conv_pos + bit\n",
        "        xor_pattern = self.hash_metadata[metadata_idx: metadata_idx + 1]\n",
        "        out = out ^ torch.where((history_slice >> bit) & 1 == 1, xor_pattern, zero_tensor)\n",
        "    \n",
        "    return out\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    history_length = history_lengths[self.slice_id]\n",
        "    conv_filter = conv_filters[self.slice_id]\n",
        "    conv_width = conv_widths[self.slice_id]\n",
        "    pooling_width = pooling_widths[self.slice_id]\n",
        "\n",
        "    # convolution and batch norm layers\n",
        "    x = self.hash_using_metadata(x, conv_width)\n",
        "    x = self.combined_embedding_table(x)\n",
        "    x = torch.transpose(x, 1, 2)\n",
        "    x = self.combined_conv(x)\n",
        "    x = self.batchnorm(x)\n",
        "    x = self.convolution_activation(x)\n",
        "\n",
        "    # pooling\n",
        "    if pooling_width == -1:\n",
        "      x = torch.sum(x, 2, keepdim=True)\n",
        "    elif pooling_width > 0:\n",
        "      x = self.pooling(x) * pooling_width    \n",
        "    x = self.sumpooling_activation(x)\n",
        "    # if(self.config['use_lstm']):\n",
        "    #   x = x.permute(0, 2, 1)\n",
        "    #   _ , (x , _ ) = self.lstm(x)\n",
        "    #   x = x.permute(0, 2, 1)\n",
        "    #   return x.reshape(-1, self.total_output_size)\n",
        "    # else:\n",
        "    return x.view(-1, self.total_output_size)\n",
        "\n",
        "  def get_output_size(self):\n",
        "    \"\"\"Returns the expected output size for the slice\n",
        "    \"\"\"\n",
        "    return self.total_output_size\n",
        "\n",
        "  def convolution_activation(self, x):\n",
        "    \"\"\"Returns post- and pre- quantization activations.\"\"\"\n",
        "    sigmoid_act = nn.Sigmoid()\n",
        "    x = sigmoid_act(x)\n",
        "\n",
        "    return x\n",
        "    \n",
        "\n",
        "  def sumpooling_activation(self, x):\n",
        "\n",
        "    hardsigmoid_act = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
        "\n",
        "    x = hardsigmoid_act(self.pooling_batchnorm(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "class FCLayer(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, activation):\n",
        "    super(FCLayer, self).__init__()\n",
        "    self.activation = activation\n",
        "\n",
        "    self.weight = nn.Parameter(torch.empty(output_dim, input_dim))\n",
        "    self.bias = nn.Parameter(torch.empty(output_dim))\n",
        "    if activation is not None:\n",
        "      self.batchnorm = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "\n",
        "    self.randomize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "   \n",
        "    weight = self.weight\n",
        "\n",
        "    x = nn.functional.linear(x, weight, bias=self.bias)\n",
        "    if self.activation is not None:\n",
        "      x = self.activation_layer(x)\n",
        "    return x\n",
        "\n",
        "  def activation_layer(self, x):\n",
        "    x = self.batchnorm(x)\n",
        "\n",
        "    relu_act = nn.ReLU(inplace=True)\n",
        "    sigmoid_act = nn.Sigmoid()\n",
        "    tanh_act = nn.Tanh()\n",
        "    hardtanh_act = nn.Hardtanh()\n",
        "\n",
        "    if self.activation == 'relu':\n",
        "      x = relu_act(x)\n",
        "    elif self.activation == 'sigmoid':\n",
        "      x = sigmoid_act(x)\n",
        "    elif self.activation == 'tanh':\n",
        "      x = tanh_act(x)\n",
        "    elif self.activation == 'hardtanh':\n",
        "      x = hardtanh_act(x)\n",
        "    else:\n",
        "      assert False\n",
        "\n",
        "    return x\n",
        "\n",
        "  def randomize_weights(self):\n",
        "    output_dim = self.weight.shape[0]\n",
        "    input_dim = self.weight.shape[1]\n",
        "    glorot_init_bound = math.sqrt(2. / (input_dim + output_dim))\n",
        "    self.weight.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "    self.bias.data.uniform_(-glorot_init_bound, +glorot_init_bound)\n",
        "\n",
        "  def l1_loss(self):\n",
        "    return torch.sum(torch.abs(self.weight))\n",
        "\n",
        "\n",
        "\n",
        "class BranchNetMLP(nn.Module):\n",
        "  def __init__(self, flattened_input_dim):\n",
        "    super(BranchNetMLP, self).__init__()\n",
        "    self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "    next_input_dim = flattened_input_dim\n",
        "    for hidden_output_dim in [8]:\n",
        "      assert hidden_output_dim > 0\n",
        "      self.hidden_layers.append(FCLayer(\n",
        "          next_input_dim, hidden_output_dim,\n",
        "          activation='tanh'))\n",
        "      next_input_dim = hidden_output_dim\n",
        "\n",
        "    self.last_layer = FCLayer(\n",
        "        next_input_dim, 1,\n",
        "        activation=None)\n",
        "\n",
        "  def forward(self, x):    \n",
        "    for i in range(len(self.hidden_layers)):\n",
        "      x = self.hidden_layers[i](x)\n",
        "    x = self.last_layer(x)\n",
        "    return x.squeeze(dim=1)\n",
        "\n",
        "  def randomize_weights(self):\n",
        "    for i in range(len([8])):\n",
        "      self.hidden_layers[i].randomize_weights()\n",
        "    self.last_layer.randomize_weights()\n",
        "\n",
        "class BranchNet(nn.Module):\n",
        "  \"\"\"\n",
        "  A Pytorch neural network module class to define BranchNet architecture.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super(BranchNet, self).__init__()\n",
        "\n",
        "    assert lists_have_equal_length(\n",
        "        [history_lengths, conv_filters,\n",
        "         conv_widths, pooling_widths])\n",
        "\n",
        "    self.history_lengths = history_lengths\n",
        "\n",
        "    num_slices = len(self.history_lengths)\n",
        "    self.slices = nn.ModuleList()\n",
        "    concatenated_slices_output_size = 0\n",
        "    for slice_id in range(num_slices):\n",
        "      if conv_filters[slice_id] > 0:\n",
        "        self.slices.append(Slice(slice_id))\n",
        "        concatenated_slices_output_size += self.slices[slice_id].get_output_size()\n",
        "      else:\n",
        "        self.slices.append(nn.ReLU()) #insert dummy module instead of a slice    \n",
        "    self.mlp = BranchNetMLP(concatenated_slices_output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #pylint: disable=arguments-differ\n",
        "    #It is expected to change forward() arguments.\n",
        "    if any(shifting_pooling):\n",
        "      global_shift = np.random.randint(max(pooling_widths), size=(x.shape[0]))\n",
        "    else:\n",
        "      global_shift = None\n",
        "\n",
        "    slice_outs = []\n",
        "    num_slices = len(self.history_lengths)\n",
        "\n",
        "    for slice_id in range(num_slices):\n",
        "      if conv_filters[slice_id] > 0:\n",
        "        x_ = extract_slice_history(x, global_shift, slice_id)\n",
        "        x_ = self.slices[slice_id](x_)\n",
        "        slice_outs.append(x_)        \n",
        "    x = torch.cat(slice_outs, dim=1)    \n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "  def train(self, mode=True):\n",
        "    super(BranchNet, self).train(mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŒŸ Model parameters: 0.01 M\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_58572/3158720859.py:58: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler     = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
            "/tmp/ipykernel_58572/3158720859.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
            "/tmp/ipykernel_58572/3158720859.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 01 â”‚ train loss 0.3407  acc 84.11% â”‚ val loss 0.0757  acc 99.70%\n",
            "   â†³ ðŸ… new best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_58572/3158720859.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
            "/tmp/ipykernel_58572/3158720859.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 02 â”‚ train loss 0.0354  acc 99.98% â”‚ val loss 0.0244  acc 99.98%\n",
            "   â†³ ðŸ… new best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_58572/3158720859.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n"
          ]
        }
      ],
      "source": [
        "import  torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BranchHistoryDataset(Dataset):\n",
        "    def __init__(self, csv_path, history_lengths):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        self.max_hist = max(history_lengths)\n",
        "        self.histories = []\n",
        "        self.targets   = torch.tensor(df[\"taken\"].values, dtype=torch.float32)\n",
        "\n",
        "        for hist_str in df[\"history\"].fillna(\"\").values:\n",
        "            bits   = [int(b) for b in hist_str.split(\",\") if b != \"\"]\n",
        "            tokens = bits[-self.max_hist:]                          # truncate\n",
        "            tokens = [0]*(self.max_hist-len(tokens)) + tokens       # left-pad\n",
        "            self.histories.append(torch.tensor(tokens, dtype=torch.long))\n",
        "\n",
        "    def __len__(self):  return len(self.targets)\n",
        "    def __getitem__(self, i):  return self.histories[i], self.targets[i]\n",
        "\n",
        "import yaml\n",
        "\n",
        "with open(\"/home/gkapakos/Desktop/ECE/10th_Semester/Architecture_of_Parallel_Systems/Project/BranchPredictionAI/KladosNet/branchnet/configs/mini_250.yaml\") as fh:          # â† the file you uploaded\n",
        "    cfg = yaml.safe_load(fh)          # cfg is now a Python dict\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "dataloader = BranchHistoryDataset(\"/home/gkapakos/Desktop/ECE/10th_Semester/Architecture_of_Parallel_Systems/Project/BranchPredictionAI/dataset.csv\", cfg['history_lengths'])\n",
        "\n",
        "train_ratio = 0.8                       # 80 % train, 20 % val\n",
        "train_len   = int(train_ratio * len(dataloader))\n",
        "val_len     = len(dataloader) - train_len\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    dataloader,\n",
        "    lengths=[train_len, val_len],\n",
        "    generator=torch.Generator().manual_seed(42)   # fix the seed once\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True,  num_workers=4)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=4)\n",
        "\n",
        "# train_branchnet_minimal.py  (excerpt)\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score          # pip install scikit-learn\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "VAL_RATIO  = 0.2\n",
        "EPOCHS     = 10\n",
        "LR         = 3e-4\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = BranchNet().to(device)\n",
        "criterion  = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler  = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "scaler     = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
        "\n",
        "print(f\"ðŸŒŸ Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f} M\")\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.train()\n",
        "    train_loss_sum, train_samples = 0.0, 0\n",
        "    train_preds,  train_labels    = [], []\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "            logits = model(X)\n",
        "            loss   = criterion(logits, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # bookkeeping\n",
        "        train_loss_sum += loss.item() * X.size(0)\n",
        "        train_samples  += X.size(0)\n",
        "\n",
        "        train_preds.append((logits > 0).cpu())   # logits>0 == prob>0.5\n",
        "        train_labels.append(y.cpu())\n",
        "\n",
        "    scheduler.step()\n",
        "    train_loss = train_loss_sum / train_samples\n",
        "    train_acc  = accuracy_score(torch.cat(train_labels),\n",
        "                                torch.cat(train_preds))\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VALIDATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.eval()\n",
        "    val_loss_sum, val_samples = 0.0, 0\n",
        "    val_preds,  val_labels    = [], []\n",
        "\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            logits   = model(X)\n",
        "            val_loss = criterion(logits, y)\n",
        "\n",
        "            val_loss_sum += val_loss.item() * X.size(0)\n",
        "            val_samples  += X.size(0)\n",
        "\n",
        "            val_preds.append((logits > 0).cpu())\n",
        "            val_labels.append(y.cpu())\n",
        "\n",
        "    val_loss = val_loss_sum / val_samples\n",
        "    val_acc  = accuracy_score(torch.cat(val_labels),\n",
        "                              torch.cat(val_preds))\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LOG / CKPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(f\"epoch {epoch:02d} â”‚ \"\n",
        "          f\"train loss {train_loss:.4f}  acc {train_acc*100:5.2f}% â”‚ \"\n",
        "          f\"val loss {val_loss:.4f}  acc {val_acc*100:5.2f}%\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"branchnet_b est.pt\")\n",
        "        print(\"   â†³ ðŸ… new best model saved\")\n",
        "\n",
        "print(f\"âœ… finished - best val loss {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
